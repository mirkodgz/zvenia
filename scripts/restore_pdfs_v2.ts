
import fs from 'fs';
import * as csv from 'fast-csv';
import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';

dotenv.config();

const SUPABASE_URL = process.env.PUBLIC_SUPABASE_URL || '';
const SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY || '';
const supabase = createClient(SUPABASE_URL, SERVICE_KEY);

const POSTS_CSV = 'd:/zvenia/migration_data/datos nuevos/z-post-limpio.csv';
const MEDIA_CSV = 'd:/zvenia/migration_data/datos nuevos/media-limpio.csv';

// MAPS
const idToCloudUrl = new Map<string, string>();
const oldUrlToCloudUrl = new Map<string, string>();

async function loadMediaMap() {
    return new Promise<void>((resolve) => {
        console.log("ðŸ“‚ Loading Media Map...");
        fs.createReadStream(MEDIA_CSV)
            .pipe(csv.parse({ headers: true }))
            .on('data', (row: any) => {
                const id = row['wp_post_id'] || row['post_id'];
                const cloudUrl = row['wp_attachment_url']; // This seems to be the Cloudinary URL in this export
                const guid = row['guid']; // This acts as the "original" URL often

                if (cloudUrl && cloudUrl.includes('cloudinary')) {
                    // Map by ID
                    if (id) idToCloudUrl.set(id.toString(), cloudUrl.trim());

                    // Map by GUID (Old URL)
                    if (guid) {
                        let cleanGuid = guid.trim();
                        // Sometimes simple filenames match
                        const filename = cleanGuid.split('/').pop();
                        if (filename) oldUrlToCloudUrl.set(filename, cloudUrl.trim());
                        oldUrlToCloudUrl.set(cleanGuid, cloudUrl.trim());
                    }
                }
            })
            .on('end', () => {
                console.log(`   âœ… Loaded Media Maps: ${idToCloudUrl.size} IDs, ${oldUrlToCloudUrl.size} URLs.`);
                resolve();
            });
    });
}

async function restorePdfs() {
    await loadMediaMap();
    console.log("ðŸš€ STARTING PDF RESTORATION...");

    let updated = 0;

    // Process Posts CSV
    fs.createReadStream(POSTS_CSV)
        .pipe(csv.parse({ headers: true }))
        .on('data', async (row: any) => {
            const slug = row['wp_post_name'] || row['post_name'];
            if (!slug) return;

            // Prioritized Metadata Keys
            const pdfVal = row['meta_pdf-text-url'] || row['meta_file'] || row['meta_upload_file'];

            if (!pdfVal || pdfVal === 'true' || pdfVal.length < 3) return;

            // RESOLVE URL
            let resolvedUrl = null;
            let method = '';

            // 1. Is it a Cloudinary URL already?
            if (pdfVal.includes('cloudinary.com')) {
                resolvedUrl = pdfVal;
                method = 'ALREADY_CLOUD';
            }
            // 2. Is it an ID?
            else if (/^\d+$/.test(pdfVal)) {
                resolvedUrl = idToCloudUrl.get(pdfVal);
                method = 'ID_MATCH';
            }
            // 3. Is it a Legacy URL?
            else {
                // Try Full Match
                resolvedUrl = oldUrlToCloudUrl.get(pdfVal);
                method = 'URL_MATCH';

                // Try Filename Match
                if (!resolvedUrl) {
                    const fname = pdfVal.split('/').pop();
                    resolvedUrl = oldUrlToCloudUrl.get(fname);
                    method = 'FILENAME_MATCH';
                }
            }

            if (resolvedUrl) {
                // Update Supabase
                const { data: posts } = await supabase.from('posts').select('id, document_url').eq('slug', slug);
                if (posts && posts.length > 0) {
                    const p = posts[0];
                    if (p.document_url !== resolvedUrl) {
                        const { error } = await supabase.from('posts').update({ document_url: resolvedUrl }).eq('id', p.id);
                        if (!error) {
                            console.log(`âœ… [${method}] Restored PDF for '${slug}': ${resolvedUrl.split('/').pop()}`);
                            updated++;
                        }
                    }
                }
            }
        })
        .on('end', () => {
            console.log("-----------------------------------------");
            // Since stream is async, we can't easily wait for DB calls here without a complex queue. 
            // But for this quantity, let's just let the loop run. 
            // In a real production script I'd use a queue.
            // For now, I'll set a timeout to print summary.
            setTimeout(() => {
                console.log(`ðŸŽ‰ PDF PROCESS COMPLETED. Estimated Updates: ${updated}`);
            }, 10000);
        });
}

restorePdfs().catch(console.error);
